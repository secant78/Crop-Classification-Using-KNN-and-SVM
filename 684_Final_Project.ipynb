{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "684_Final_Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/secant78/Crop-Classification-Using-KNN-and-SVM/blob/main/684_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fr4dzzbklyq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c8d4c2-8f9d-4cbc-aa35-734d1a2cdd42"
      },
      "source": [
        "import os\n",
        "import math\n",
        "import string\n",
        "#import data set to list'\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "#\"/content/drive/My Drive/\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pSAz9mqTlxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebaaffac-d3c7-4267-94c3-5706c61db891"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzm_EJ-ykodB"
      },
      "source": [
        "fileTrain = r'/content/drive/My Drive/CISC 684/forest_mapping/WinnipegDataset.txt'\n",
        "#filetrain1 = r'/content/drive/My Drive/CISC 684/forest_mapping/training.csv'\n",
        "#fileTest = r'/content/drive/My Drive/CISC 684/forest_mapping/testing.csv'\n",
        "\n",
        "dataTrain = pd.read_csv(fileTrain) #opens the file in read mode\n",
        "\n",
        "#datatrain1 = pd.read_csv(filetrain1)\n",
        "#datatest = pd.read_csv(fileTest)\n",
        "#dataTest = pd.read_csv(fileTest)\n",
        " #puts the file into an array\n",
        "        #words['a'] = words['a'].str.join(\" \") \n",
        "        #print(words)\n",
        "\n",
        "\n",
        "\n",
        "#datatrain1 = datatrain1[datatrain1[\"class\"] != \"s \"]\n",
        "#datatrain1 = datatrain1[datatrain1[\"class\"] != \"d \"]\n",
        "\n",
        "#datatest = datatest[datatest[\"class\"] != \"s \"]\n",
        "\\\n",
        "#datatest = datatest[datatest[\"class\"] != \"d \"]\n",
        "\n",
        "#datatest.head()\n",
        "#dataTest.head()\n",
        "\n",
        "#pcaData = pd.read_csv(filePCA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "H7IH5E2xbdSo",
        "outputId": "d5fd4bd1-f2cb-4337-fba8-15f1b73bfac0"
      },
      "source": [
        "dataTrain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>f1</th>\n",
              "      <th>f2</th>\n",
              "      <th>f3</th>\n",
              "      <th>f4</th>\n",
              "      <th>f5</th>\n",
              "      <th>f6</th>\n",
              "      <th>f7</th>\n",
              "      <th>f8</th>\n",
              "      <th>f9</th>\n",
              "      <th>f10</th>\n",
              "      <th>f11</th>\n",
              "      <th>f12</th>\n",
              "      <th>f13</th>\n",
              "      <th>f14</th>\n",
              "      <th>f15</th>\n",
              "      <th>f16</th>\n",
              "      <th>f17</th>\n",
              "      <th>f18</th>\n",
              "      <th>f19</th>\n",
              "      <th>f20</th>\n",
              "      <th>f21</th>\n",
              "      <th>f22</th>\n",
              "      <th>f23</th>\n",
              "      <th>f24</th>\n",
              "      <th>f25</th>\n",
              "      <th>f26</th>\n",
              "      <th>f27</th>\n",
              "      <th>f28</th>\n",
              "      <th>f29</th>\n",
              "      <th>f30</th>\n",
              "      <th>f31</th>\n",
              "      <th>f32</th>\n",
              "      <th>f33</th>\n",
              "      <th>f34</th>\n",
              "      <th>f35</th>\n",
              "      <th>f36</th>\n",
              "      <th>f37</th>\n",
              "      <th>f38</th>\n",
              "      <th>f39</th>\n",
              "      <th>...</th>\n",
              "      <th>f135</th>\n",
              "      <th>f136</th>\n",
              "      <th>f137</th>\n",
              "      <th>f138</th>\n",
              "      <th>f139</th>\n",
              "      <th>f140</th>\n",
              "      <th>f141</th>\n",
              "      <th>f142</th>\n",
              "      <th>f143</th>\n",
              "      <th>f144</th>\n",
              "      <th>f145</th>\n",
              "      <th>f146</th>\n",
              "      <th>f147</th>\n",
              "      <th>f148</th>\n",
              "      <th>f149</th>\n",
              "      <th>f150</th>\n",
              "      <th>f151</th>\n",
              "      <th>f152</th>\n",
              "      <th>f153</th>\n",
              "      <th>f154</th>\n",
              "      <th>f155</th>\n",
              "      <th>f156</th>\n",
              "      <th>f157</th>\n",
              "      <th>f158</th>\n",
              "      <th>f159</th>\n",
              "      <th>f160</th>\n",
              "      <th>f161</th>\n",
              "      <th>f162</th>\n",
              "      <th>f163</th>\n",
              "      <th>f164</th>\n",
              "      <th>f165</th>\n",
              "      <th>f166</th>\n",
              "      <th>f167</th>\n",
              "      <th>f168</th>\n",
              "      <th>f169</th>\n",
              "      <th>f170</th>\n",
              "      <th>f171</th>\n",
              "      <th>f172</th>\n",
              "      <th>f173</th>\n",
              "      <th>f174</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-13.55900</td>\n",
              "      <td>-21.4070</td>\n",
              "      <td>-11.40400</td>\n",
              "      <td>-15.24800</td>\n",
              "      <td>-11.92300</td>\n",
              "      <td>-15.29100</td>\n",
              "      <td>-2.15480</td>\n",
              "      <td>-7.8474</td>\n",
              "      <td>-10.0020</td>\n",
              "      <td>0.042390</td>\n",
              "      <td>3.32530</td>\n",
              "      <td>3.36770</td>\n",
              "      <td>0.35631</td>\n",
              "      <td>0.058490</td>\n",
              "      <td>0.58520</td>\n",
              "      <td>0.24150</td>\n",
              "      <td>0.51934</td>\n",
              "      <td>0.23916</td>\n",
              "      <td>-0.62424</td>\n",
              "      <td>-0.81493</td>\n",
              "      <td>-0.70844</td>\n",
              "      <td>-0.65641</td>\n",
              "      <td>-0.195680</td>\n",
              "      <td>-0.63160</td>\n",
              "      <td>0.091945</td>\n",
              "      <td>0.026703</td>\n",
              "      <td>0.005017</td>\n",
              "      <td>0.62019</td>\n",
              "      <td>0.68370</td>\n",
              "      <td>44.369</td>\n",
              "      <td>0.42402</td>\n",
              "      <td>0.196170</td>\n",
              "      <td>0.25967</td>\n",
              "      <td>0.120130</td>\n",
              "      <td>0.054561</td>\n",
              "      <td>0.162260</td>\n",
              "      <td>-11.92300</td>\n",
              "      <td>-12.82300</td>\n",
              "      <td>-21.4070</td>\n",
              "      <td>...</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>0.650770</td>\n",
              "      <td>6711</td>\n",
              "      <td>6143</td>\n",
              "      <td>4570</td>\n",
              "      <td>5064</td>\n",
              "      <td>8212</td>\n",
              "      <td>0.284930</td>\n",
              "      <td>1.7969</td>\n",
              "      <td>1.3442</td>\n",
              "      <td>-0.61941</td>\n",
              "      <td>0.54346</td>\n",
              "      <td>0.42738</td>\n",
              "      <td>0.14683</td>\n",
              "      <td>0.144130</td>\n",
              "      <td>0.58593</td>\n",
              "      <td>0.23712</td>\n",
              "      <td>1.6216</td>\n",
              "      <td>0.23712</td>\n",
              "      <td>294110.0</td>\n",
              "      <td>0.051277</td>\n",
              "      <td>2199.40</td>\n",
              "      <td>92560.0</td>\n",
              "      <td>1.10810</td>\n",
              "      <td>48.444</td>\n",
              "      <td>3.13580</td>\n",
              "      <td>0.57778</td>\n",
              "      <td>2.44440</td>\n",
              "      <td>1.11110</td>\n",
              "      <td>1.8310</td>\n",
              "      <td>0.18519</td>\n",
              "      <td>0.726020</td>\n",
              "      <td>5.3333</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.29489</td>\n",
              "      <td>9.77780</td>\n",
              "      <td>2.44440</td>\n",
              "      <td>1.67700</td>\n",
              "      <td>0.20988</td>\n",
              "      <td>0.65422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-12.80200</td>\n",
              "      <td>-20.3350</td>\n",
              "      <td>-10.39900</td>\n",
              "      <td>-14.13200</td>\n",
              "      <td>-11.09600</td>\n",
              "      <td>-14.36100</td>\n",
              "      <td>-2.40390</td>\n",
              "      <td>-7.5330</td>\n",
              "      <td>-9.9369</td>\n",
              "      <td>0.228420</td>\n",
              "      <td>3.03600</td>\n",
              "      <td>3.26440</td>\n",
              "      <td>0.34295</td>\n",
              "      <td>0.060525</td>\n",
              "      <td>0.59652</td>\n",
              "      <td>0.25249</td>\n",
              "      <td>0.50796</td>\n",
              "      <td>0.23955</td>\n",
              "      <td>-0.57229</td>\n",
              "      <td>-0.74854</td>\n",
              "      <td>-0.64839</td>\n",
              "      <td>-0.62810</td>\n",
              "      <td>-0.188250</td>\n",
              "      <td>-0.55448</td>\n",
              "      <td>0.115710</td>\n",
              "      <td>0.031183</td>\n",
              "      <td>0.006051</td>\n",
              "      <td>0.60356</td>\n",
              "      <td>0.67496</td>\n",
              "      <td>44.992</td>\n",
              "      <td>0.40738</td>\n",
              "      <td>0.196180</td>\n",
              "      <td>0.26758</td>\n",
              "      <td>0.128860</td>\n",
              "      <td>0.052298</td>\n",
              "      <td>0.158260</td>\n",
              "      <td>-11.09600</td>\n",
              "      <td>-11.80500</td>\n",
              "      <td>-20.3350</td>\n",
              "      <td>...</td>\n",
              "      <td>0.30864</td>\n",
              "      <td>0.104830</td>\n",
              "      <td>6274</td>\n",
              "      <td>5084</td>\n",
              "      <td>3297</td>\n",
              "      <td>3777</td>\n",
              "      <td>8214</td>\n",
              "      <td>0.427160</td>\n",
              "      <td>2.4914</td>\n",
              "      <td>1.5420</td>\n",
              "      <td>-0.64500</td>\n",
              "      <td>0.92501</td>\n",
              "      <td>0.64071</td>\n",
              "      <td>0.21322</td>\n",
              "      <td>0.235370</td>\n",
              "      <td>0.75089</td>\n",
              "      <td>0.37003</td>\n",
              "      <td>2.1747</td>\n",
              "      <td>0.37003</td>\n",
              "      <td>412400.0</td>\n",
              "      <td>0.067854</td>\n",
              "      <td>2338.40</td>\n",
              "      <td>100280.0</td>\n",
              "      <td>1.14560</td>\n",
              "      <td>49.778</td>\n",
              "      <td>0.39506</td>\n",
              "      <td>0.46667</td>\n",
              "      <td>1.33330</td>\n",
              "      <td>1.11110</td>\n",
              "      <td>1.2149</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>-0.487510</td>\n",
              "      <td>2.1111</td>\n",
              "      <td>0.098765</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.84869</td>\n",
              "      <td>0.50617</td>\n",
              "      <td>-0.18898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-12.43100</td>\n",
              "      <td>-19.9020</td>\n",
              "      <td>-10.07400</td>\n",
              "      <td>-13.59800</td>\n",
              "      <td>-10.82900</td>\n",
              "      <td>-14.04800</td>\n",
              "      <td>-2.35660</td>\n",
              "      <td>-7.4717</td>\n",
              "      <td>-9.8283</td>\n",
              "      <td>0.449780</td>\n",
              "      <td>2.76870</td>\n",
              "      <td>3.21850</td>\n",
              "      <td>0.34489</td>\n",
              "      <td>0.061731</td>\n",
              "      <td>0.59338</td>\n",
              "      <td>0.26362</td>\n",
              "      <td>0.49870</td>\n",
              "      <td>0.23768</td>\n",
              "      <td>-0.53347</td>\n",
              "      <td>-0.70253</td>\n",
              "      <td>-0.58846</td>\n",
              "      <td>-0.61836</td>\n",
              "      <td>-0.178040</td>\n",
              "      <td>-0.48642</td>\n",
              "      <td>0.127130</td>\n",
              "      <td>0.032382</td>\n",
              "      <td>0.006162</td>\n",
              "      <td>0.58683</td>\n",
              "      <td>0.68024</td>\n",
              "      <td>45.466</td>\n",
              "      <td>0.39919</td>\n",
              "      <td>0.187640</td>\n",
              "      <td>0.28105</td>\n",
              "      <td>0.132110</td>\n",
              "      <td>0.048473</td>\n",
              "      <td>0.148780</td>\n",
              "      <td>-10.82900</td>\n",
              "      <td>-11.37700</td>\n",
              "      <td>-19.9020</td>\n",
              "      <td>...</td>\n",
              "      <td>0.30864</td>\n",
              "      <td>0.613940</td>\n",
              "      <td>6215</td>\n",
              "      <td>5035</td>\n",
              "      <td>3033</td>\n",
              "      <td>3837</td>\n",
              "      <td>8588</td>\n",
              "      <td>0.478010</td>\n",
              "      <td>2.8315</td>\n",
              "      <td>1.6601</td>\n",
              "      <td>-0.70049</td>\n",
              "      <td>1.03530</td>\n",
              "      <td>0.71699</td>\n",
              "      <td>0.24814</td>\n",
              "      <td>0.260810</td>\n",
              "      <td>0.80946</td>\n",
              "      <td>0.38237</td>\n",
              "      <td>2.2382</td>\n",
              "      <td>0.38237</td>\n",
              "      <td>439570.0</td>\n",
              "      <td>0.117030</td>\n",
              "      <td>3321.30</td>\n",
              "      <td>128320.0</td>\n",
              "      <td>1.26510</td>\n",
              "      <td>49.444</td>\n",
              "      <td>0.24691</td>\n",
              "      <td>0.61111</td>\n",
              "      <td>0.77778</td>\n",
              "      <td>0.77778</td>\n",
              "      <td>1.3689</td>\n",
              "      <td>0.25926</td>\n",
              "      <td>0.252980</td>\n",
              "      <td>2.2222</td>\n",
              "      <td>0.172840</td>\n",
              "      <td>0.68889</td>\n",
              "      <td>0.88889</td>\n",
              "      <td>0.66667</td>\n",
              "      <td>1.27300</td>\n",
              "      <td>0.30864</td>\n",
              "      <td>0.10483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-12.68900</td>\n",
              "      <td>-19.5290</td>\n",
              "      <td>-10.02800</td>\n",
              "      <td>-13.35000</td>\n",
              "      <td>-11.05600</td>\n",
              "      <td>-14.01400</td>\n",
              "      <td>-2.66110</td>\n",
              "      <td>-6.8396</td>\n",
              "      <td>-9.5006</td>\n",
              "      <td>0.663780</td>\n",
              "      <td>2.29420</td>\n",
              "      <td>2.95800</td>\n",
              "      <td>0.32760</td>\n",
              "      <td>0.067825</td>\n",
              "      <td>0.60457</td>\n",
              "      <td>0.28135</td>\n",
              "      <td>0.47717</td>\n",
              "      <td>0.24148</td>\n",
              "      <td>-0.50405</td>\n",
              "      <td>-0.66998</td>\n",
              "      <td>-0.52543</td>\n",
              "      <td>-0.61169</td>\n",
              "      <td>-0.175070</td>\n",
              "      <td>-0.43576</td>\n",
              "      <td>0.127200</td>\n",
              "      <td>0.031091</td>\n",
              "      <td>0.006040</td>\n",
              "      <td>0.57769</td>\n",
              "      <td>0.67468</td>\n",
              "      <td>46.654</td>\n",
              "      <td>0.38976</td>\n",
              "      <td>0.187930</td>\n",
              "      <td>0.28492</td>\n",
              "      <td>0.137380</td>\n",
              "      <td>0.047480</td>\n",
              "      <td>0.147010</td>\n",
              "      <td>-11.05600</td>\n",
              "      <td>-11.26300</td>\n",
              "      <td>-19.5290</td>\n",
              "      <td>...</td>\n",
              "      <td>0.16049</td>\n",
              "      <td>0.064018</td>\n",
              "      <td>6836</td>\n",
              "      <td>5745</td>\n",
              "      <td>4212</td>\n",
              "      <td>4534</td>\n",
              "      <td>7691</td>\n",
              "      <td>0.292280</td>\n",
              "      <td>1.8260</td>\n",
              "      <td>1.3640</td>\n",
              "      <td>-0.47512</td>\n",
              "      <td>0.65772</td>\n",
              "      <td>0.43840</td>\n",
              "      <td>0.15396</td>\n",
              "      <td>0.144830</td>\n",
              "      <td>0.60147</td>\n",
              "      <td>0.25824</td>\n",
              "      <td>1.6963</td>\n",
              "      <td>0.25824</td>\n",
              "      <td>296240.0</td>\n",
              "      <td>0.036817</td>\n",
              "      <td>1748.10</td>\n",
              "      <td>80640.0</td>\n",
              "      <td>1.07640</td>\n",
              "      <td>50.667</td>\n",
              "      <td>0.88889</td>\n",
              "      <td>0.61111</td>\n",
              "      <td>0.77778</td>\n",
              "      <td>0.77778</td>\n",
              "      <td>1.8892</td>\n",
              "      <td>0.16049</td>\n",
              "      <td>0.437500</td>\n",
              "      <td>4.1111</td>\n",
              "      <td>0.320990</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>1.14910</td>\n",
              "      <td>0.38272</td>\n",
              "      <td>0.41603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>-12.68600</td>\n",
              "      <td>-19.2780</td>\n",
              "      <td>-9.81850</td>\n",
              "      <td>-13.10800</td>\n",
              "      <td>-10.93200</td>\n",
              "      <td>-13.93900</td>\n",
              "      <td>-2.86750</td>\n",
              "      <td>-6.5919</td>\n",
              "      <td>-9.4594</td>\n",
              "      <td>0.831430</td>\n",
              "      <td>2.17560</td>\n",
              "      <td>3.00700</td>\n",
              "      <td>0.31701</td>\n",
              "      <td>0.069483</td>\n",
              "      <td>0.61351</td>\n",
              "      <td>0.28768</td>\n",
              "      <td>0.47476</td>\n",
              "      <td>0.23756</td>\n",
              "      <td>-0.50314</td>\n",
              "      <td>-0.68221</td>\n",
              "      <td>-0.50731</td>\n",
              "      <td>-0.59134</td>\n",
              "      <td>-0.175050</td>\n",
              "      <td>-0.45195</td>\n",
              "      <td>0.131550</td>\n",
              "      <td>0.031960</td>\n",
              "      <td>0.006439</td>\n",
              "      <td>0.57937</td>\n",
              "      <td>0.66460</td>\n",
              "      <td>46.828</td>\n",
              "      <td>0.38505</td>\n",
              "      <td>0.194320</td>\n",
              "      <td>0.27955</td>\n",
              "      <td>0.141080</td>\n",
              "      <td>0.048950</td>\n",
              "      <td>0.151560</td>\n",
              "      <td>-10.93200</td>\n",
              "      <td>-11.10900</td>\n",
              "      <td>-19.2780</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20988</td>\n",
              "      <td>0.657600</td>\n",
              "      <td>6682</td>\n",
              "      <td>5883</td>\n",
              "      <td>4434</td>\n",
              "      <td>4627</td>\n",
              "      <td>7072</td>\n",
              "      <td>0.229270</td>\n",
              "      <td>1.5949</td>\n",
              "      <td>1.3268</td>\n",
              "      <td>-0.40120</td>\n",
              "      <td>0.52776</td>\n",
              "      <td>0.34389</td>\n",
              "      <td>0.14045</td>\n",
              "      <td>0.091779</td>\n",
              "      <td>0.53551</td>\n",
              "      <td>0.20899</td>\n",
              "      <td>1.5284</td>\n",
              "      <td>0.20899</td>\n",
              "      <td>232610.0</td>\n",
              "      <td>0.021300</td>\n",
              "      <td>1365.40</td>\n",
              "      <td>69540.0</td>\n",
              "      <td>1.04350</td>\n",
              "      <td>51.222</td>\n",
              "      <td>0.39506</td>\n",
              "      <td>0.56667</td>\n",
              "      <td>1.66670</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.7351</td>\n",
              "      <td>0.18519</td>\n",
              "      <td>0.350000</td>\n",
              "      <td>4.0000</td>\n",
              "      <td>0.444440</td>\n",
              "      <td>0.68889</td>\n",
              "      <td>0.88889</td>\n",
              "      <td>0.66667</td>\n",
              "      <td>1.58110</td>\n",
              "      <td>0.20988</td>\n",
              "      <td>0.50000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325829</th>\n",
              "      <td>7</td>\n",
              "      <td>2.48230</td>\n",
              "      <td>-7.6870</td>\n",
              "      <td>1.07950</td>\n",
              "      <td>0.74318</td>\n",
              "      <td>-0.94070</td>\n",
              "      <td>0.90493</td>\n",
              "      <td>1.40280</td>\n",
              "      <td>-10.1690</td>\n",
              "      <td>-8.7665</td>\n",
              "      <td>-0.161750</td>\n",
              "      <td>-1.68390</td>\n",
              "      <td>-1.84560</td>\n",
              "      <td>0.54941</td>\n",
              "      <td>0.052840</td>\n",
              "      <td>0.39775</td>\n",
              "      <td>0.36811</td>\n",
              "      <td>0.24980</td>\n",
              "      <td>0.38208</td>\n",
              "      <td>-1.58110</td>\n",
              "      <td>-1.68310</td>\n",
              "      <td>-0.17427</td>\n",
              "      <td>-1.65010</td>\n",
              "      <td>-0.040115</td>\n",
              "      <td>-1.53410</td>\n",
              "      <td>2.421000</td>\n",
              "      <td>0.755430</td>\n",
              "      <td>0.047157</td>\n",
              "      <td>0.56149</td>\n",
              "      <td>0.88249</td>\n",
              "      <td>63.745</td>\n",
              "      <td>0.49551</td>\n",
              "      <td>0.065983</td>\n",
              "      <td>0.38698</td>\n",
              "      <td>0.051531</td>\n",
              "      <td>0.019479</td>\n",
              "      <td>0.058516</td>\n",
              "      <td>-0.94070</td>\n",
              "      <td>3.51790</td>\n",
              "      <td>-7.6870</td>\n",
              "      <td>...</td>\n",
              "      <td>0.50617</td>\n",
              "      <td>-0.188980</td>\n",
              "      <td>5960</td>\n",
              "      <td>5510</td>\n",
              "      <td>3023</td>\n",
              "      <td>4711</td>\n",
              "      <td>9327</td>\n",
              "      <td>0.510450</td>\n",
              "      <td>3.0853</td>\n",
              "      <td>1.8227</td>\n",
              "      <td>-0.91447</td>\n",
              "      <td>0.98173</td>\n",
              "      <td>0.76564</td>\n",
              "      <td>0.29146</td>\n",
              "      <td>0.257260</td>\n",
              "      <td>0.86830</td>\n",
              "      <td>0.32882</td>\n",
              "      <td>1.9798</td>\n",
              "      <td>0.32882</td>\n",
              "      <td>423430.0</td>\n",
              "      <td>0.218260</td>\n",
              "      <td>5811.10</td>\n",
              "      <td>200760.0</td>\n",
              "      <td>1.55840</td>\n",
              "      <td>47.000</td>\n",
              "      <td>9.55560</td>\n",
              "      <td>0.36706</td>\n",
              "      <td>10.55600</td>\n",
              "      <td>2.55560</td>\n",
              "      <td>2.0432</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>0.760800</td>\n",
              "      <td>2.3333</td>\n",
              "      <td>0.222220</td>\n",
              "      <td>0.88889</td>\n",
              "      <td>0.22222</td>\n",
              "      <td>0.22222</td>\n",
              "      <td>1.06090</td>\n",
              "      <td>0.35802</td>\n",
              "      <td>0.63246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325830</th>\n",
              "      <td>7</td>\n",
              "      <td>2.52340</td>\n",
              "      <td>-7.6745</td>\n",
              "      <td>1.08680</td>\n",
              "      <td>0.76189</td>\n",
              "      <td>-0.91177</td>\n",
              "      <td>0.93663</td>\n",
              "      <td>1.43660</td>\n",
              "      <td>-10.1980</td>\n",
              "      <td>-8.7614</td>\n",
              "      <td>-0.174730</td>\n",
              "      <td>-1.67370</td>\n",
              "      <td>-1.84840</td>\n",
              "      <td>0.55130</td>\n",
              "      <td>0.052673</td>\n",
              "      <td>0.39603</td>\n",
              "      <td>0.36748</td>\n",
              "      <td>0.24996</td>\n",
              "      <td>0.38256</td>\n",
              "      <td>-1.55830</td>\n",
              "      <td>-1.65400</td>\n",
              "      <td>-0.16971</td>\n",
              "      <td>-1.62440</td>\n",
              "      <td>-0.039090</td>\n",
              "      <td>-1.51290</td>\n",
              "      <td>2.438700</td>\n",
              "      <td>0.758140</td>\n",
              "      <td>0.046243</td>\n",
              "      <td>0.55955</td>\n",
              "      <td>0.88502</td>\n",
              "      <td>63.669</td>\n",
              "      <td>0.49522</td>\n",
              "      <td>0.064335</td>\n",
              "      <td>0.38981</td>\n",
              "      <td>0.050641</td>\n",
              "      <td>0.018962</td>\n",
              "      <td>0.057036</td>\n",
              "      <td>-0.91177</td>\n",
              "      <td>3.54420</td>\n",
              "      <td>-7.6745</td>\n",
              "      <td>...</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>0.823180</td>\n",
              "      <td>7649</td>\n",
              "      <td>6544</td>\n",
              "      <td>4690</td>\n",
              "      <td>4823</td>\n",
              "      <td>7104</td>\n",
              "      <td>0.204680</td>\n",
              "      <td>1.5147</td>\n",
              "      <td>1.3953</td>\n",
              "      <td>-0.27280</td>\n",
              "      <td>0.60815</td>\n",
              "      <td>0.30701</td>\n",
              "      <td>0.16503</td>\n",
              "      <td>0.041032</td>\n",
              "      <td>0.56030</td>\n",
              "      <td>0.19125</td>\n",
              "      <td>1.4729</td>\n",
              "      <td>0.19125</td>\n",
              "      <td>222500.0</td>\n",
              "      <td>0.013981</td>\n",
              "      <td>1460.90</td>\n",
              "      <td>82140.0</td>\n",
              "      <td>1.02840</td>\n",
              "      <td>49.667</td>\n",
              "      <td>2.22220</td>\n",
              "      <td>0.37094</td>\n",
              "      <td>4.88890</td>\n",
              "      <td>1.77780</td>\n",
              "      <td>2.0432</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>-0.383990</td>\n",
              "      <td>6.0000</td>\n",
              "      <td>10.444000</td>\n",
              "      <td>0.12684</td>\n",
              "      <td>19.55600</td>\n",
              "      <td>4.00000</td>\n",
              "      <td>2.19720</td>\n",
              "      <td>0.11111</td>\n",
              "      <td>0.81224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325831</th>\n",
              "      <td>7</td>\n",
              "      <td>-1.92700</td>\n",
              "      <td>-11.4160</td>\n",
              "      <td>-2.43540</td>\n",
              "      <td>-3.45370</td>\n",
              "      <td>-4.15130</td>\n",
              "      <td>-3.48100</td>\n",
              "      <td>0.50845</td>\n",
              "      <td>-9.4886</td>\n",
              "      <td>-8.9802</td>\n",
              "      <td>0.027269</td>\n",
              "      <td>-0.69758</td>\n",
              "      <td>-0.67031</td>\n",
              "      <td>0.49950</td>\n",
              "      <td>0.056191</td>\n",
              "      <td>0.44431</td>\n",
              "      <td>0.35145</td>\n",
              "      <td>0.29930</td>\n",
              "      <td>0.34925</td>\n",
              "      <td>-2.19560</td>\n",
              "      <td>-2.46680</td>\n",
              "      <td>-0.16691</td>\n",
              "      <td>-2.23240</td>\n",
              "      <td>-0.043728</td>\n",
              "      <td>-2.19360</td>\n",
              "      <td>0.889060</td>\n",
              "      <td>0.376290</td>\n",
              "      <td>0.019241</td>\n",
              "      <td>0.61651</td>\n",
              "      <td>0.90271</td>\n",
              "      <td>60.734</td>\n",
              "      <td>0.55653</td>\n",
              "      <td>0.059982</td>\n",
              "      <td>0.34618</td>\n",
              "      <td>0.037311</td>\n",
              "      <td>0.021642</td>\n",
              "      <td>0.059914</td>\n",
              "      <td>-4.15130</td>\n",
              "      <td>-0.82003</td>\n",
              "      <td>-11.4160</td>\n",
              "      <td>...</td>\n",
              "      <td>0.20988</td>\n",
              "      <td>0.561270</td>\n",
              "      <td>6004</td>\n",
              "      <td>5343</td>\n",
              "      <td>3444</td>\n",
              "      <td>4255</td>\n",
              "      <td>8071</td>\n",
              "      <td>0.401820</td>\n",
              "      <td>2.3435</td>\n",
              "      <td>1.5514</td>\n",
              "      <td>-0.70992</td>\n",
              "      <td>0.80257</td>\n",
              "      <td>0.60271</td>\n",
              "      <td>0.21611</td>\n",
              "      <td>0.203370</td>\n",
              "      <td>0.74539</td>\n",
              "      <td>0.30959</td>\n",
              "      <td>1.8968</td>\n",
              "      <td>0.30959</td>\n",
              "      <td>354320.0</td>\n",
              "      <td>0.105340</td>\n",
              "      <td>3239.50</td>\n",
              "      <td>124620.0</td>\n",
              "      <td>1.23550</td>\n",
              "      <td>48.778</td>\n",
              "      <td>6.61730</td>\n",
              "      <td>0.34061</td>\n",
              "      <td>9.00000</td>\n",
              "      <td>2.33330</td>\n",
              "      <td>2.0432</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>0.754830</td>\n",
              "      <td>2.3333</td>\n",
              "      <td>0.222220</td>\n",
              "      <td>0.83333</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>1.27300</td>\n",
              "      <td>0.30864</td>\n",
              "      <td>0.31623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325832</th>\n",
              "      <td>7</td>\n",
              "      <td>0.12483</td>\n",
              "      <td>-10.1440</td>\n",
              "      <td>-0.62193</td>\n",
              "      <td>-1.54210</td>\n",
              "      <td>-2.31000</td>\n",
              "      <td>-1.52500</td>\n",
              "      <td>0.74676</td>\n",
              "      <td>-10.2690</td>\n",
              "      <td>-9.5218</td>\n",
              "      <td>-0.017135</td>\n",
              "      <td>-0.76782</td>\n",
              "      <td>-0.78496</td>\n",
              "      <td>0.51652</td>\n",
              "      <td>0.048555</td>\n",
              "      <td>0.43492</td>\n",
              "      <td>0.35188</td>\n",
              "      <td>0.29486</td>\n",
              "      <td>0.35327</td>\n",
              "      <td>-2.00020</td>\n",
              "      <td>-2.36840</td>\n",
              "      <td>-0.21772</td>\n",
              "      <td>-2.06770</td>\n",
              "      <td>-0.047450</td>\n",
              "      <td>-1.97390</td>\n",
              "      <td>1.390500</td>\n",
              "      <td>0.569520</td>\n",
              "      <td>0.032453</td>\n",
              "      <td>0.61538</td>\n",
              "      <td>0.89218</td>\n",
              "      <td>60.757</td>\n",
              "      <td>0.54903</td>\n",
              "      <td>0.066350</td>\n",
              "      <td>0.34315</td>\n",
              "      <td>0.041470</td>\n",
              "      <td>0.023339</td>\n",
              "      <td>0.065150</td>\n",
              "      <td>-2.31000</td>\n",
              "      <td>1.16690</td>\n",
              "      <td>-10.1440</td>\n",
              "      <td>...</td>\n",
              "      <td>0.23457</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>6234</td>\n",
              "      <td>5469</td>\n",
              "      <td>3442</td>\n",
              "      <td>4472</td>\n",
              "      <td>6766</td>\n",
              "      <td>0.325630</td>\n",
              "      <td>1.9657</td>\n",
              "      <td>1.5889</td>\n",
              "      <td>-0.42977</td>\n",
              "      <td>0.82470</td>\n",
              "      <td>0.48842</td>\n",
              "      <td>0.22747</td>\n",
              "      <td>0.106010</td>\n",
              "      <td>0.73427</td>\n",
              "      <td>0.20413</td>\n",
              "      <td>1.5130</td>\n",
              "      <td>0.20413</td>\n",
              "      <td>216430.0</td>\n",
              "      <td>0.130150</td>\n",
              "      <td>3867.20</td>\n",
              "      <td>142880.0</td>\n",
              "      <td>1.29920</td>\n",
              "      <td>51.556</td>\n",
              "      <td>0.24691</td>\n",
              "      <td>0.77778</td>\n",
              "      <td>0.44444</td>\n",
              "      <td>0.44444</td>\n",
              "      <td>1.2149</td>\n",
              "      <td>0.33333</td>\n",
              "      <td>0.059761</td>\n",
              "      <td>3.0000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.94444</td>\n",
              "      <td>0.11111</td>\n",
              "      <td>0.11111</td>\n",
              "      <td>0.34883</td>\n",
              "      <td>0.80247</td>\n",
              "      <td>0.18898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325833</th>\n",
              "      <td>7</td>\n",
              "      <td>0.20063</td>\n",
              "      <td>-10.0500</td>\n",
              "      <td>-0.59892</td>\n",
              "      <td>-1.50120</td>\n",
              "      <td>-2.25060</td>\n",
              "      <td>-1.46320</td>\n",
              "      <td>0.79955</td>\n",
              "      <td>-10.2510</td>\n",
              "      <td>-9.4514</td>\n",
              "      <td>-0.038057</td>\n",
              "      <td>-0.74936</td>\n",
              "      <td>-0.78742</td>\n",
              "      <td>0.51915</td>\n",
              "      <td>0.049000</td>\n",
              "      <td>0.43185</td>\n",
              "      <td>0.35084</td>\n",
              "      <td>0.29524</td>\n",
              "      <td>0.35393</td>\n",
              "      <td>-1.95170</td>\n",
              "      <td>-2.29460</td>\n",
              "      <td>-0.21988</td>\n",
              "      <td>-2.02270</td>\n",
              "      <td>-0.048298</td>\n",
              "      <td>-1.92140</td>\n",
              "      <td>1.408400</td>\n",
              "      <td>0.575490</td>\n",
              "      <td>0.033400</td>\n",
              "      <td>0.61584</td>\n",
              "      <td>0.89029</td>\n",
              "      <td>60.623</td>\n",
              "      <td>0.54828</td>\n",
              "      <td>0.067562</td>\n",
              "      <td>0.34202</td>\n",
              "      <td>0.042145</td>\n",
              "      <td>0.023714</td>\n",
              "      <td>0.066226</td>\n",
              "      <td>-2.25060</td>\n",
              "      <td>1.21520</td>\n",
              "      <td>-10.0500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.11111</td>\n",
              "      <td>0.704060</td>\n",
              "      <td>7980</td>\n",
              "      <td>6950</td>\n",
              "      <td>5297</td>\n",
              "      <td>5004</td>\n",
              "      <td>6458</td>\n",
              "      <td>0.098766</td>\n",
              "      <td>1.2192</td>\n",
              "      <td>1.3121</td>\n",
              "      <td>-0.13432</td>\n",
              "      <td>0.42372</td>\n",
              "      <td>0.14814</td>\n",
              "      <td>0.13497</td>\n",
              "      <td>-0.036695</td>\n",
              "      <td>0.41138</td>\n",
              "      <td>0.12685</td>\n",
              "      <td>1.2906</td>\n",
              "      <td>0.12685</td>\n",
              "      <td>150320.0</td>\n",
              "      <td>-0.028444</td>\n",
              "      <td>224.02</td>\n",
              "      <td>48540.0</td>\n",
              "      <td>0.94469</td>\n",
              "      <td>51.333</td>\n",
              "      <td>1.33330</td>\n",
              "      <td>0.49542</td>\n",
              "      <td>3.11110</td>\n",
              "      <td>1.33330</td>\n",
              "      <td>2.1972</td>\n",
              "      <td>0.11111</td>\n",
              "      <td>0.168430</td>\n",
              "      <td>6.6667</td>\n",
              "      <td>11.111000</td>\n",
              "      <td>0.35569</td>\n",
              "      <td>14.33300</td>\n",
              "      <td>3.00000</td>\n",
              "      <td>2.04320</td>\n",
              "      <td>0.13580</td>\n",
              "      <td>0.72732</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>325834 rows Ã— 175 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        label        f1       f2        f3  ...     f171     f172     f173     f174\n",
              "0           1 -13.55900 -21.4070 -11.40400  ...  2.44440  1.67700  0.20988  0.65422\n",
              "1           1 -12.80200 -20.3350 -10.39900  ...  0.33333  0.84869  0.50617 -0.18898\n",
              "2           1 -12.43100 -19.9020 -10.07400  ...  0.66667  1.27300  0.30864  0.10483\n",
              "3           1 -12.68900 -19.5290 -10.02800  ...  0.33333  1.14910  0.38272  0.41603\n",
              "4           1 -12.68600 -19.2780  -9.81850  ...  0.66667  1.58110  0.20988  0.50000\n",
              "...       ...       ...      ...       ...  ...      ...      ...      ...      ...\n",
              "325829      7   2.48230  -7.6870   1.07950  ...  0.22222  1.06090  0.35802  0.63246\n",
              "325830      7   2.52340  -7.6745   1.08680  ...  4.00000  2.19720  0.11111  0.81224\n",
              "325831      7  -1.92700 -11.4160  -2.43540  ...  0.33333  1.27300  0.30864  0.31623\n",
              "325832      7   0.12483 -10.1440  -0.62193  ...  0.11111  0.34883  0.80247  0.18898\n",
              "325833      7   0.20063 -10.0500  -0.59892  ...  3.00000  2.04320  0.13580  0.72732\n",
              "\n",
              "[325834 rows x 175 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fvBK3IOFZBa",
        "outputId": "ffdd6185-eeaa-44a4-a6f8-3b3c93d093f6"
      },
      "source": [
        "dataTrain.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYElAvRfl2QY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e45c28e-e86d-4aa4-e67a-3bade297be94"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = dataTrain.iloc[:,1:].values\n",
        "\n",
        "y = dataTrain.iloc[:,0].values\n",
        "\n",
        "#X_train = dataTrain.iloc[:,1:].values\n",
        "\n",
        "#y_train = dataTrain.iloc[:,0].values\n",
        "\n",
        "#X_test = datatest.iloc[:,1:].values\n",
        "\n",
        "#y_test = datatest.iloc[:,0].values\n",
        "\n",
        "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size=0.0001, random_state=0)\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.0002, random_state=0)\n",
        "X_train3, X_test3, y_train3, y_test3 = train_test_split(X, y, test_size=0.0003, random_state=0)\n",
        "X_train4, X_test4, y_train4, y_test4 = train_test_split(X, y, test_size=0.00015, random_state=0)\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(X, y, test_size=0.00025, random_state=0)\n",
        "\n",
        "print(X_train1.shape)\n",
        "print(X_test1.shape)\n",
        "\n",
        "print(X_train2.shape)\n",
        "print(X_test2.shape)\n",
        "\n",
        "print(X_train3.shape)\n",
        "print(X_test3.shape)\n",
        "\n",
        "print(X_train4.shape)\n",
        "print(X_test4.shape)\n",
        "\n",
        "print(X_train5.shape)\n",
        "print(X_test5.shape)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_train1 = sc.fit_transform(X_train1)\n",
        "X_test1 = sc.transform(X_test1)\n",
        "\n",
        "X_train2 = sc.fit_transform(X_train2)\n",
        "X_test2 = sc.transform(X_test2)\n",
        "\n",
        "X_train3 = sc.fit_transform(X_train3)\n",
        "X_test3 = sc.transform(X_test3)\n",
        "\n",
        "X_train4 = sc.fit_transform(X_train4)\n",
        "X_test4 = sc.transform(X_test4)\n",
        "\n",
        "X_train5 = sc.fit_transform(X_train5)\n",
        "X_test5 = sc.transform(X_test5)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(325801, 174)\n",
            "(33, 174)\n",
            "(325768, 174)\n",
            "(66, 174)\n",
            "(325736, 174)\n",
            "(98, 174)\n",
            "(325785, 174)\n",
            "(49, 174)\n",
            "(325752, 174)\n",
            "(82, 174)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pTJtCi6iAih"
      },
      "source": [
        "import pandas as pd\r\n",
        "setSizeTrain = {'Train Sets':['Set1','Set2','Set3','Set4','Set5'],'Size':[325801, 325785, 325768, 325752, 325736]}   \r\n",
        "              #'LDA': [5.263], 'QDA': [2.92397], 'Logistic Regression': [2.92], 'SVM': [0.0351], 'Neural Network':[1.169], 'Classification Tree':[5.85] }\r\n",
        "data_set_size_train = pd.DataFrame(setSizeTrain)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "IeomI2g9iSfk",
        "outputId": "1cda3418-f948-4c7c-e547-7e9b2ff2def0"
      },
      "source": [
        "data_set_size_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Train Sets</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Set1</td>\n",
              "      <td>325801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Set2</td>\n",
              "      <td>325785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Set3</td>\n",
              "      <td>325768</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Set4</td>\n",
              "      <td>325752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Set5</td>\n",
              "      <td>325736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Train Sets    Size\n",
              "0       Set1  325801\n",
              "1       Set2  325785\n",
              "2       Set3  325768\n",
              "3       Set4  325752\n",
              "4       Set5  325736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itUelr7oeEeq"
      },
      "source": [
        "import pandas as pd\r\n",
        "setSize = {'Test Sets':['Set1','Set2','Set3','Set4','Set5'],'Size':[33, 49, 66, 82, 98]}   \r\n",
        "              #'LDA': [5.263], 'QDA': [2.92397], 'Logistic Regression': [2.92], 'SVM': [0.0351], 'Neural Network':[1.169], 'Classification Tree':[5.85] }\r\n",
        "data_set_size_df = pd.DataFrame(setSize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "cFI5KO4theo0",
        "outputId": "1f919052-f021-4453-c13e-9f0f2f8c3f90"
      },
      "source": [
        "data_set_size_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Sets</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Set1</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Set2</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Set3</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Set4</td>\n",
              "      <td>82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Set5</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Test Sets  Size\n",
              "0      Set1    33\n",
              "1      Set2    49\n",
              "2      Set3    66\n",
              "3      Set4    82\n",
              "4      Set5    98"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv7zrRKmyI1K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80309369-0cbe-477e-e3d5-446551f32937"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6, 6, 5, ..., 4, 3, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnqRphYD_oVQ",
        "outputId": "fc6a6c56-83c3-49b5-f3d5-9f72b701d34d"
      },
      "source": [
        "y_train.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UClYDq0o79Ib"
      },
      "source": [
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1WzzLrx3GFT"
      },
      "source": [
        "class KNN:\r\n",
        "  def __init__(self,k=1):\r\n",
        "        self.k = k\r\n",
        "  def predict_test_class(self,NN_df, y_train_):\r\n",
        "\r\n",
        "    y_train_df = pd.DataFrame()\r\n",
        "    y_train_df['counter'] = range(y_train_.shape[0])\r\n",
        "    y_train_df['y_vals'] = y_train_\r\n",
        "  \r\n",
        "\r\n",
        "    y_val_df = pd.merge(y_train_df, NN_df)\r\n",
        "  \r\n",
        "\r\n",
        "    max_y_val = y_val_df['y_vals'].mode()\r\n",
        "    return max_y_val\r\n",
        "\r\n",
        "  def distance_to_center(self,train,test,y_train_):\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    distance = np.zeros((1, train.shape[0]))\r\n",
        "\r\n",
        "    for train_row in range(train.shape[0]):\r\n",
        "      distance[0,train_row] = (np.linalg.norm((train[train_row,:] - test[:])))**2\r\n",
        "\r\n",
        "\r\n",
        "    distance_df = pd.DataFrame()\r\n",
        "    distance_df['counter'] = range(distance.shape[1])\r\n",
        "    distance_df['dist'] = distance[0,:]\r\n",
        "\r\n",
        "    distance_df = distance_df.sort_values(by=['dist'])\r\n",
        "\r\n",
        "\r\n",
        "    nearest_neighbors = distance_df.iloc[0:self.k,:]\r\n",
        "    predicted_class = self.predict_test_class(nearest_neighbors,y_train_)\r\n",
        "  \r\n",
        "    return predicted_class\r\n",
        "  def get_predictions(self,X_train_,X_test_,y_train_,y_test_):\r\n",
        "    \r\n",
        "    pred_class = np.zeros((1, X_test_.shape[0]))\r\n",
        "    for i in range(X_test_.shape[0]):\r\n",
        "      pred_class[0,i] = self.distance_to_center(X_train_,X_test_[i,:],y_train_)\r\n",
        "      #print(pred_class)\r\n",
        "\r\n",
        "    return pred_class\r\n",
        "\r\n",
        "  def measure_accuracy(self,predicted, actual):\r\n",
        "\r\n",
        "    nCorrect = 0\r\n",
        "    nIncorrect = 0\r\n",
        "\r\n",
        "    for i in range(predicted.shape[1]):\r\n",
        "      if(predicted[0,i] == actual[i]):\r\n",
        "        nCorrect += 1\r\n",
        "\r\n",
        "      else:\r\n",
        "        nIncorrect +=1\r\n",
        "\r\n",
        "    print(\"Number Correct: \", nCorrect)\r\n",
        "    print(\"Number Incorrect: \", nIncorrect)\r\n",
        "    print(\"Classification Accuracy: \", nCorrect/predicted.shape[1])\r\n",
        "\r\n",
        "    return nCorrect/predicted.shape[1]\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5fsc4t844MT"
      },
      "source": [
        "KNN_model = KNN(k=8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kRbhmQ-E1NN",
        "outputId": "987c3f5a-f260-402f-f0df-601d5d569a8f"
      },
      "source": [
        "print(y_train1)\r\n",
        "print(y_train1.shape)\r\n",
        "print(y_train2.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6 6 5 ... 4 3 6]\n",
            "(325801,)\n",
            "(325768,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jI8oWlr53a52",
        "outputId": "48696ac9-e16c-419f-a816-91a253884756"
      },
      "source": [
        "%%time\r\n",
        "predKNN_1 = KNN_model.get_predictions(X_train1,X_test1,y_train1,y_test1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 26s, sys: 693 ms, total: 1min 27s\n",
            "Wall time: 1min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3xHXLEcOw2t",
        "outputId": "b65b89fb-c965-41bd-88bf-25918a67ee9b"
      },
      "source": [
        "KNN_1_acc = KNN_model.measure_accuracy(predKNN_1,y_test1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  33\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG8tvr_F_W0O",
        "outputId": "bddde165-1672-44f6-be64-69c471d7b54e"
      },
      "source": [
        "%%time\r\n",
        "predKNN_2 = KNN_model.get_predictions(X_train2,X_test2,y_train2,y_test2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 56s, sys: 1.48 s, total: 2min 58s\n",
            "Wall time: 2min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_OqK9WLPAzn",
        "outputId": "12bfc4a6-24a6-498c-a46b-2fc694ccac98"
      },
      "source": [
        "knn_acc_2 = KNN_model.measure_accuracy(predKNN_2,y_test2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  66\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwEwvHfkAASp",
        "outputId": "bf5a2557-b658-479a-c937-a513a9d1ef72"
      },
      "source": [
        "%%time\r\n",
        "predKNN_3 = KNN_model.get_predictions(X_train3,X_test3,y_train3,y_test3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 22s, sys: 2.3 s, total: 4min 24s\n",
            "Wall time: 4min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbt3VytSPL4y",
        "outputId": "f65e0647-4e66-41aa-ab79-a3389011ff3f"
      },
      "source": [
        "knn_acc_3 = KNN_model.measure_accuracy(predKNN_3,y_test3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  98\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExidVizHDS7T",
        "outputId": "4095cac8-fa1f-47fb-ab0d-9fef2bab2ce5"
      },
      "source": [
        "%%time\r\n",
        "predKNN_4 = KNN_model.get_predictions(X_train4,X_test4,y_train4,y_test4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 9s, sys: 1.13 s, total: 2min 11s\n",
            "Wall time: 2min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dsQPJqoPPsR",
        "outputId": "6e360e0c-50ca-4560-93e4-3be7b5f43502"
      },
      "source": [
        "knn_acc_4 = KNN_model.measure_accuracy(predKNN_4,y_test4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  49\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6UVrCq9DT1D",
        "outputId": "5e4ab292-839a-4942-b9e4-8b5becb4bfd7"
      },
      "source": [
        "%%time\r\n",
        "predKNN_5 = KNN_model.get_predictions(X_train5,X_test5,y_train5,y_test5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3min 37s, sys: 1.97 s, total: 3min 39s\n",
            "Wall time: 3min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOJfeXJ1PTl8",
        "outputId": "69bcaa59-0b1b-4d35-b54f-2fd771d16906"
      },
      "source": [
        "knn_acc_5 = KNN_model.measure_accuracy(predKNN_5,y_test5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  82\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl4hQ4mdLWC3"
      },
      "source": [
        "import pandas as pd\r\n",
        "modelsUsedKNN = {'Sets':['Set1','Set2','Set3','Set4','Set5'],'Accuracy':[1, 1, 1, 1, 1]}   \r\n",
        "              #'LDA': [5.263], 'QDA': [2.92397], 'Logistic Regression': [2.92], 'SVM': [0.0351], 'Neural Network':[1.169], 'Classification Tree':[5.85] }\r\n",
        "acc_KNN_df = pd.DataFrame(modelsUsedKNN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "vuPIwMM3aoll",
        "outputId": "59717514-7d7a-4ab4-ff2c-d70d34096dbf"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "sns.set_context('paper')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# create plot\r\n",
        "sns.barplot(x = 'Sets', y = 'Accuracy', data = acc_KNN_df, palette=\"cubehelix\")\r\n",
        "plt.title('KNN Accuracy On Different Sizes of Test Set')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Q8-8u38bKog"
      },
      "source": [
        "import pandas as pd\r\n",
        "modelsUsedTime = {'Sets':['Set1','Set2','Set3','Set4','Set5'],'Time':[87, 131, 178, 219, 264]}   \r\n",
        "              #'LDA': [5.263], 'QDA': [2.92397], 'Logistic Regression': [2.92], 'SVM': [0.0351], 'Neural Network':[1.169], 'Classification Tree':[5.85] }\r\n",
        "time_KNN_df = pd.DataFrame(modelsUsedTime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "O_aRY2jSflZZ",
        "outputId": "fbeb1229-fca0-47ad-bffc-9ef573d988f1"
      },
      "source": [
        "time_KNN_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sets</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Set1</td>\n",
              "      <td>87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Set2</td>\n",
              "      <td>131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Set3</td>\n",
              "      <td>178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Set4</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Set5</td>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sets  Time\n",
              "0  Set1    87\n",
              "1  Set2   131\n",
              "2  Set3   178\n",
              "3  Set4   219\n",
              "4  Set5   264"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "QY1JoOYai2_R",
        "outputId": "f8e16d06-6bd5-4331-bbd5-49b4f8a0d8fc"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "sns.set_context('paper')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# create plot\r\n",
        "sns.barplot(x = 'Sets', y = 'Time', data = time_KNN_df, palette=\"cubehelix\")\r\n",
        "plt.title('KNN Computation Time (in seconds) On Different Sizes of Test Set')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRhSWVE0QBP3"
      },
      "source": [
        "knn5_model = KNN(k=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IB8PGRTZP34h",
        "outputId": "8f26c0d4-ce87-46c8-b2d0-77e99cb09014"
      },
      "source": [
        "%%time\r\n",
        "predKNN5_1 = knn5_model.get_predictions(X_train1,X_test1,y_train1,y_test1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 26s, sys: 789 ms, total: 1min 27s\n",
            "Wall time: 1min 27s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIhclsOXRipj"
      },
      "source": [
        "%%time\r\n",
        "predKNN5_2 = knn5_model.get_predictions(X_train2,X_test2,y_train2,y_test2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoLqIbPlRjcT"
      },
      "source": [
        "%%time\r\n",
        "predKNN5_3 = knn5_model.get_predictions(X_train3,X_test3,y_train3,y_test3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh231z4FRkmK"
      },
      "source": [
        "%%time\r\n",
        "predKNN5_4 = knn5_model.get_predictions(X_train4,X_test4,y_train4,y_test4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPBi6FlwRlXY"
      },
      "source": [
        "%%time\r\n",
        "predKNN5_5 = knn5_model.get_predictions(X_train5,X_test5,y_train5,y_test5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jaFJqn0D9l8",
        "outputId": "beacc7ed-6bbc-46da-d088-237facd89169"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33, 174)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smdJz0Vt5bqd",
        "outputId": "4cb37c3e-10dc-45bb-bcfe-70df97e5be0c"
      },
      "source": [
        "accuracy_KNN = KNN_model.measure_accuracy(pred,y_test)\r\n",
        "print(accuracy_KNN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE66uQzD5uR4"
      },
      "source": [
        "class SVM:\r\n",
        "    def __init__(self,learning_rate = .001,lamb = .01, max_iter=10000):\r\n",
        "        self.learning_rate = learning_rate\r\n",
        "        self.lamb = lamb\r\n",
        "        self.max_iter = int(max_iter)\r\n",
        "        \r\n",
        "    \r\n",
        "    def initialize(self, X_tr):\r\n",
        "        self.X_train = X_tr\r\n",
        "        self.X_train_shape = X_tr.shape\r\n",
        "        self.b = 0\r\n",
        "        self.epochs = 1\r\n",
        "        self.weights = np.zeros(self.X_train.shape[1])\r\n",
        "        \r\n",
        "        \r\n",
        "\r\n",
        "    def fit(self, X_tr, y_train):\r\n",
        "        self.initialize(X_tr)\r\n",
        "\r\n",
        "\r\n",
        "        epoch_iter = self.epochs\r\n",
        "        while(epoch_iter < self.max_iter):\r\n",
        "          y = np.dot(self.X_train, self.weights)\r\n",
        "          prod = y * y_train\r\n",
        "          #print(prod.shape)\r\n",
        "          for val in range(len(prod)):\r\n",
        "            if(prod[val] >=1):\r\n",
        "              cost = 0\r\n",
        "              self.weights -= self.learning_rate*2*(1/epoch_iter)*self.weights\r\n",
        "          #print(weights)\r\n",
        "            else:\r\n",
        "              cost = 1 - val\r\n",
        "              self.weights = self.weights - self.learning_rate * (-2*(1/epoch_iter)*self.weights - np.dot(self.X_train[val],y_train[val]))\r\n",
        "              self.b -= self.learning_rate * y_train[val]\r\n",
        "\r\n",
        "              epoch_iter +=1\r\n",
        "\r\n",
        "       \r\n",
        "\r\n",
        "    def predict(self, X_test):\r\n",
        "        y_pred = np.dot(self.weights, X_test.T)\r\n",
        "        predicted_class = np.zeros(len(y_pred))\r\n",
        "        for index, val in enumerate(y_pred):\r\n",
        "          if(val > 0):\r\n",
        "            predicted_class[index] = 1\r\n",
        "          else:\r\n",
        "            predicted_class[index] = 0\r\n",
        "\r\n",
        "        return predicted_class\r\n",
        "      \r\n",
        "    def score(self, predicted, y_test):\r\n",
        "\r\n",
        "        nCorrect = 0\r\n",
        "        nIncorrect = 0\r\n",
        "\r\n",
        "        for i in range(len(predicted)):\r\n",
        "          if(predicted[i] == y_test[i]):\r\n",
        "            nCorrect += 1\r\n",
        "\r\n",
        "          else:\r\n",
        "            nIncorrect +=1\r\n",
        "\r\n",
        "        print(\"Number Correct: \", nCorrect)\r\n",
        "        print(\"Number Incorrect: \", nIncorrect)\r\n",
        "        print(\"Classification Accuracy: \", nCorrect/len(predicted))\r\n",
        "\r\n",
        "        return nCorrect/len(predicted)\r\n",
        "\r\n",
        "\r\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CG6GMQZumwU"
      },
      "source": [
        "\r\n",
        "import copy\r\n",
        "\r\n",
        "def oneVsRestClassifier(SVM_mod, y_train,y_test,X_train,X_test):\r\n",
        "\r\n",
        "  num_classes = np.max(y_train) + 1\r\n",
        "  accuracy_arr = np.zeros(num_classes)\r\n",
        "  for i in range(num_classes):\r\n",
        "    #print ('\\nThe %d/%dth svm classifier training...' % (i+1, num_classes))\r\n",
        "    \r\n",
        "    y_train_svm = copy.deepcopy(y_train)\r\n",
        "    y_test_svm = copy.deepcopy(y_test)\r\n",
        "    idxs_i = y_train_svm == i\r\n",
        "    idxs_i_test = y_test_svm == i\r\n",
        "    #print(idxs_i)\r\n",
        "    #print(y_train)\r\n",
        "    #print(y_train_svm)\r\n",
        "    y_train_svm[idxs_i] = 1\r\n",
        "    y_train_svm[~idxs_i] = 0\r\n",
        "    #print(y_train_svm)\r\n",
        "    y_test_svm[idxs_i_test] = 1\r\n",
        "    y_test_svm[~idxs_i_test] = 0\r\n",
        "    #logistic = Logistic()\r\n",
        "    #loss = logistic.train(X_train, y_train_logistic, method='sgd', batch_size=200, learning_rate=1e-6,\r\n",
        "    #          reg = 1e3, num_iters=1000, verbose=True, vectorized=True)\r\n",
        "    #losses.append(loss)\r\n",
        "    #svm_classifiers.append(svm_2(X_train,X_test,y_train_svm))\r\n",
        "\r\n",
        "    SVM_mod.fit(X_train,y_train_svm)\r\n",
        "    y_pred = SVM_mod.predict(X_test)\r\n",
        "    #weights, b= svm_2(X_train,X_test,y_train_svm)\r\n",
        "    #print(weights)\r\n",
        "    #pred_class = predict_svm(weights, X_test)\r\n",
        "    #print(pred_class)\r\n",
        "    class_acc = SVM_mod.score(y_pred, y_test_svm)\r\n",
        "    #print(class_acc)\r\n",
        "    accuracy_arr[i] = class_acc\r\n",
        "  acc_mean = np.mean(accuracy_arr)\r\n",
        "  \r\n",
        "  return acc_mean\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHMSn7l6VdeG"
      },
      "source": [
        "SVM_model1 = SVM(max_iter=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTU4CQLR9BgC",
        "outputId": "58c7152d-c9a8-40e0-a47b-aa1c3878b27a"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM1 = oneVsRestClassifier(SVM_model1,y_train1,y_test1,X_train1,X_test1)\r\n",
        "print('Accuracy 1: ', accuracy_SVM1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  33\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  26\n",
            "Number Incorrect:  7\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  21\n",
            "Number Incorrect:  12\n",
            "Classification Accuracy:  0.6363636363636364\n",
            "Number Correct:  26\n",
            "Number Incorrect:  7\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  28\n",
            "Number Incorrect:  5\n",
            "Classification Accuracy:  0.8484848484848485\n",
            "Number Correct:  20\n",
            "Number Incorrect:  13\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Number Correct:  25\n",
            "Number Incorrect:  8\n",
            "Classification Accuracy:  0.7575757575757576\n",
            "Number Correct:  20\n",
            "Number Incorrect:  13\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Accuracy 1:  0.7537878787878788\n",
            "CPU times: user 30.9 s, sys: 1.1 s, total: 32 s\n",
            "Wall time: 30.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0l0xcI5Ew2NM",
        "outputId": "2f40c874-7946-4c7d-b8cc-f2f3c646147b"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM2 = oneVsRestClassifier(SVM_model1,y_train2,y_test2,X_train2,X_test2)\r\n",
        "print('Accuracy 2: ', accuracy_SVM2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  66\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  50\n",
            "Number Incorrect:  16\n",
            "Classification Accuracy:  0.7575757575757576\n",
            "Number Correct:  40\n",
            "Number Incorrect:  26\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Number Correct:  55\n",
            "Number Incorrect:  11\n",
            "Classification Accuracy:  0.8333333333333334\n",
            "Number Correct:  52\n",
            "Number Incorrect:  14\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  39\n",
            "Number Incorrect:  27\n",
            "Classification Accuracy:  0.5909090909090909\n",
            "Number Correct:  52\n",
            "Number Incorrect:  14\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  40\n",
            "Number Incorrect:  26\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Accuracy 2:  0.7462121212121213\n",
            "CPU times: user 30.6 s, sys: 1.1 s, total: 31.7 s\n",
            "Wall time: 30.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3SNlPJEHqw8",
        "outputId": "25ea2579-c5c4-463c-840d-9a6af2d31e6c"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM3 = oneVsRestClassifier(SVM_model1,y_train3,y_test3,X_train3,X_test3)\r\n",
        "print('Accuracy 3: ', accuracy_SVM3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  98\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  74\n",
            "Number Incorrect:  24\n",
            "Classification Accuracy:  0.7551020408163265\n",
            "Number Correct:  58\n",
            "Number Incorrect:  40\n",
            "Classification Accuracy:  0.5918367346938775\n",
            "Number Correct:  82\n",
            "Number Incorrect:  16\n",
            "Classification Accuracy:  0.8367346938775511\n",
            "Number Correct:  78\n",
            "Number Incorrect:  20\n",
            "Classification Accuracy:  0.7959183673469388\n",
            "Number Correct:  61\n",
            "Number Incorrect:  37\n",
            "Classification Accuracy:  0.6224489795918368\n",
            "Number Correct:  73\n",
            "Number Incorrect:  25\n",
            "Classification Accuracy:  0.7448979591836735\n",
            "Number Correct:  58\n",
            "Number Incorrect:  40\n",
            "Classification Accuracy:  0.5918367346938775\n",
            "Accuracy 3:  0.7423469387755102\n",
            "CPU times: user 30.4 s, sys: 1.05 s, total: 31.5 s\n",
            "Wall time: 30.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i67drI9IH2Hm",
        "outputId": "4285fb41-b623-4166-94e8-a3af197f657d"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM4 = oneVsRestClassifier(SVM_model1,y_train4,y_test4,X_train4,X_test4)\r\n",
        "print('Accuracy 4: ', accuracy_SVM4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  49\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  39\n",
            "Number Incorrect:  10\n",
            "Classification Accuracy:  0.7959183673469388\n",
            "Number Correct:  31\n",
            "Number Incorrect:  18\n",
            "Classification Accuracy:  0.6326530612244898\n",
            "Number Correct:  40\n",
            "Number Incorrect:  9\n",
            "Classification Accuracy:  0.8163265306122449\n",
            "Number Correct:  40\n",
            "Number Incorrect:  9\n",
            "Classification Accuracy:  0.8163265306122449\n",
            "Number Correct:  27\n",
            "Number Incorrect:  22\n",
            "Classification Accuracy:  0.5510204081632653\n",
            "Number Correct:  37\n",
            "Number Incorrect:  12\n",
            "Classification Accuracy:  0.7551020408163265\n",
            "Number Correct:  31\n",
            "Number Incorrect:  18\n",
            "Classification Accuracy:  0.6326530612244898\n",
            "Accuracy 4:  0.75\n",
            "CPU times: user 30.5 s, sys: 1.02 s, total: 31.5 s\n",
            "Wall time: 30.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2uZfBenH53N",
        "outputId": "a86b3038-167d-4a6e-b164-48055d5a9d87"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM5 = oneVsRestClassifier(SVM_model1,y_train5,y_test5,X_train5,X_test5)\r\n",
        "print('Accuracy 5: ', accuracy_SVM5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  82\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  61\n",
            "Number Incorrect:  21\n",
            "Classification Accuracy:  0.7439024390243902\n",
            "Number Correct:  48\n",
            "Number Incorrect:  34\n",
            "Classification Accuracy:  0.5853658536585366\n",
            "Number Correct:  67\n",
            "Number Incorrect:  15\n",
            "Classification Accuracy:  0.8170731707317073\n",
            "Number Correct:  64\n",
            "Number Incorrect:  18\n",
            "Classification Accuracy:  0.7804878048780488\n",
            "Number Correct:  51\n",
            "Number Incorrect:  31\n",
            "Classification Accuracy:  0.6219512195121951\n",
            "Number Correct:  63\n",
            "Number Incorrect:  19\n",
            "Classification Accuracy:  0.7682926829268293\n",
            "Number Correct:  47\n",
            "Number Incorrect:  35\n",
            "Classification Accuracy:  0.573170731707317\n",
            "Accuracy 5:  0.7362804878048781\n",
            "CPU times: user 30.5 s, sys: 1.04 s, total: 31.6 s\n",
            "Wall time: 30.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oooPQCRdILbO"
      },
      "source": [
        "import pandas as pd\r\n",
        "modelsUsed = {'Sets':['Set1','Set2','Set3','Set4','Set5'],'Accuracy':[.754, .746, .742, .75, .736]}   \r\n",
        "              #'LDA': [5.263], 'QDA': [2.92397], 'Logistic Regression': [2.92], 'SVM': [0.0351], 'Neural Network':[1.169], 'Classification Tree':[5.85] }\r\n",
        "acc_svm_df = pd.DataFrame(modelsUsed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "gMnA866gKAx1",
        "outputId": "2a3caa32-1ecf-4b35-c1e6-6f10a3fac866"
      },
      "source": [
        "acc_svm_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sets</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Set1</td>\n",
              "      <td>0.754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Set2</td>\n",
              "      <td>0.746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Set3</td>\n",
              "      <td>0.742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Set4</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Set5</td>\n",
              "      <td>0.736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sets  Accuracy\n",
              "0  Set1     0.754\n",
              "1  Set2     0.746\n",
              "2  Set3     0.742\n",
              "3  Set4     0.750\n",
              "4  Set5     0.736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "W7R2x6QIJlWT",
        "outputId": "12bcf255-1e9a-4bd4-f662-6cf2d1d708f9"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "sns.set_context('paper')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# create plot\r\n",
        "sns.barplot(x = 'Sets', y = 'Accuracy', data = acc_svm_df, palette=\"cubehelix\")\r\n",
        "plt.title('SVM Accuracy On Different Sizes of Test Set')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFH1Qq-dJ76B"
      },
      "source": [
        "import pandas as pd\r\n",
        "modelsUsedTime = {'Sets':['Set1','Set2','Set3','Set4','Set5'],'Time':[31.3, 31, 32.2, 32.1, 30.8]}   \r\n",
        "              #'LDA': [5.263], 'QDA': [2.92397], 'Logistic Regression': [2.92], 'SVM': [0.0351], 'Neural Network':[1.169], 'Classification Tree':[5.85] }\r\n",
        "time_svm_df = pd.DataFrame(modelsUsedTime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "LY_slzwSKXsH",
        "outputId": "0f1aff41-53a1-4fe7-bdd3-034767415a2d"
      },
      "source": [
        "time_svm_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sets</th>\n",
              "      <th>Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Set1</td>\n",
              "      <td>31.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Set2</td>\n",
              "      <td>31.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Set3</td>\n",
              "      <td>32.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Set4</td>\n",
              "      <td>32.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Set5</td>\n",
              "      <td>30.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Sets  Time\n",
              "0  Set1  31.3\n",
              "1  Set2  31.0\n",
              "2  Set3  32.2\n",
              "3  Set4  32.1\n",
              "4  Set5  30.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "_YgZiEMkKYpj",
        "outputId": "252b8581-0653-47f2-a56c-5fc03888c914"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "sns.set_context('paper')\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# create plot\r\n",
        "sns.barplot(x = 'Sets', y = 'Time', data = time_svm_df, palette=\"cubehelix\")\r\n",
        "plt.title('SVM Computation Time (in seconds) On Different Sizes of Test Set')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWnin7e-Srok"
      },
      "source": [
        "SVM_model2 = SVM(learning_rate = .01,lamb = .1, max_iter = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcOPW49JKiTK",
        "outputId": "1da01a19-49cd-4f5c-c44c-df85c697ee86"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM1_model2 = oneVsRestClassifier(SVM_model2,y_train1,y_test1,X_train1,X_test1)\r\n",
        "print('Accuracy 1: ', accuracy_SVM1_model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  33\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  26\n",
            "Number Incorrect:  7\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  21\n",
            "Number Incorrect:  12\n",
            "Classification Accuracy:  0.6363636363636364\n",
            "Number Correct:  26\n",
            "Number Incorrect:  7\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  28\n",
            "Number Incorrect:  5\n",
            "Classification Accuracy:  0.8484848484848485\n",
            "Number Correct:  20\n",
            "Number Incorrect:  13\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Number Correct:  25\n",
            "Number Incorrect:  8\n",
            "Classification Accuracy:  0.7575757575757576\n",
            "Number Correct:  20\n",
            "Number Incorrect:  13\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Accuracy 1:  0.7537878787878788\n",
            "CPU times: user 30.8 s, sys: 1.02 s, total: 31.8 s\n",
            "Wall time: 30.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZg9Yae-R_tV",
        "outputId": "38d5c227-2c0b-475f-aadb-4fb34119b75d"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM2_model2 = oneVsRestClassifier(SVM_model2,y_train2,y_test2,X_train2,X_test2)\r\n",
        "print('Accuracy 2: ', accuracy_SVM2_model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  66\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  50\n",
            "Number Incorrect:  16\n",
            "Classification Accuracy:  0.7575757575757576\n",
            "Number Correct:  40\n",
            "Number Incorrect:  26\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Number Correct:  55\n",
            "Number Incorrect:  11\n",
            "Classification Accuracy:  0.8333333333333334\n",
            "Number Correct:  52\n",
            "Number Incorrect:  14\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  39\n",
            "Number Incorrect:  27\n",
            "Classification Accuracy:  0.5909090909090909\n",
            "Number Correct:  52\n",
            "Number Incorrect:  14\n",
            "Classification Accuracy:  0.7878787878787878\n",
            "Number Correct:  40\n",
            "Number Incorrect:  26\n",
            "Classification Accuracy:  0.6060606060606061\n",
            "Accuracy 2:  0.7462121212121213\n",
            "CPU times: user 31 s, sys: 1.11 s, total: 32.1 s\n",
            "Wall time: 30.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgW5uad8SAS8",
        "outputId": "066de85a-241f-455b-ee40-4ba753d6e6a9"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM3_model2 = oneVsRestClassifier(SVM_model2,y_train3,y_test3,X_train3,X_test3)\r\n",
        "print('Accuracy 3: ', accuracy_SVM3_model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  98\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  74\n",
            "Number Incorrect:  24\n",
            "Classification Accuracy:  0.7551020408163265\n",
            "Number Correct:  58\n",
            "Number Incorrect:  40\n",
            "Classification Accuracy:  0.5918367346938775\n",
            "Number Correct:  82\n",
            "Number Incorrect:  16\n",
            "Classification Accuracy:  0.8367346938775511\n",
            "Number Correct:  78\n",
            "Number Incorrect:  20\n",
            "Classification Accuracy:  0.7959183673469388\n",
            "Number Correct:  61\n",
            "Number Incorrect:  37\n",
            "Classification Accuracy:  0.6224489795918368\n",
            "Number Correct:  73\n",
            "Number Incorrect:  25\n",
            "Classification Accuracy:  0.7448979591836735\n",
            "Number Correct:  58\n",
            "Number Incorrect:  40\n",
            "Classification Accuracy:  0.5918367346938775\n",
            "Accuracy 3:  0.7423469387755102\n",
            "CPU times: user 30.7 s, sys: 1.1 s, total: 31.8 s\n",
            "Wall time: 30.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-9_zgGbSA6R",
        "outputId": "755181c5-85f8-4ee1-9d03-8f4a1b0567d5"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM4_model2 = oneVsRestClassifier(SVM_model2, y_train4,y_test4,X_train4,X_test4)\r\n",
        "print('Accuracy 4: ', accuracy_SVM4_model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  49\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  39\n",
            "Number Incorrect:  10\n",
            "Classification Accuracy:  0.7959183673469388\n",
            "Number Correct:  31\n",
            "Number Incorrect:  18\n",
            "Classification Accuracy:  0.6326530612244898\n",
            "Number Correct:  40\n",
            "Number Incorrect:  9\n",
            "Classification Accuracy:  0.8163265306122449\n",
            "Number Correct:  40\n",
            "Number Incorrect:  9\n",
            "Classification Accuracy:  0.8163265306122449\n",
            "Number Correct:  27\n",
            "Number Incorrect:  22\n",
            "Classification Accuracy:  0.5510204081632653\n",
            "Number Correct:  37\n",
            "Number Incorrect:  12\n",
            "Classification Accuracy:  0.7551020408163265\n",
            "Number Correct:  31\n",
            "Number Incorrect:  18\n",
            "Classification Accuracy:  0.6326530612244898\n",
            "Accuracy 4:  0.75\n",
            "CPU times: user 30.8 s, sys: 1.14 s, total: 32 s\n",
            "Wall time: 30.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuGry8inSBYd",
        "outputId": "443e5bcb-baa7-4a28-909c-e6ceaa10a26a"
      },
      "source": [
        "%%time\r\n",
        "\r\n",
        "accuracy_SVM5_model2 = oneVsRestClassifier(SVM_model2, y_train5,y_test5,X_train5,X_test5)\r\n",
        "print('Accuracy 5: ', accuracy_SVM5_model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Correct:  82\n",
            "Number Incorrect:  0\n",
            "Classification Accuracy:  1.0\n",
            "Number Correct:  61\n",
            "Number Incorrect:  21\n",
            "Classification Accuracy:  0.7439024390243902\n",
            "Number Correct:  48\n",
            "Number Incorrect:  34\n",
            "Classification Accuracy:  0.5853658536585366\n",
            "Number Correct:  67\n",
            "Number Incorrect:  15\n",
            "Classification Accuracy:  0.8170731707317073\n",
            "Number Correct:  64\n",
            "Number Incorrect:  18\n",
            "Classification Accuracy:  0.7804878048780488\n",
            "Number Correct:  51\n",
            "Number Incorrect:  31\n",
            "Classification Accuracy:  0.6219512195121951\n",
            "Number Correct:  63\n",
            "Number Incorrect:  19\n",
            "Classification Accuracy:  0.7682926829268293\n",
            "Number Correct:  47\n",
            "Number Incorrect:  35\n",
            "Classification Accuracy:  0.573170731707317\n",
            "Accuracy 5:  0.7362804878048781\n",
            "CPU times: user 30.6 s, sys: 1.01 s, total: 31.6 s\n",
            "Wall time: 30.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYnhSqj2UKJ7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}